#!/usr/bin/env python3
"""
ç®€å•çš„ SentencePiece tokenizer æµ‹è¯•è„šæœ¬
"""

import argparse
import os

import sentencepiece as smp


def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯• SentencePiece tokenizer")
    parser.add_argument(
        "--bpe-model",
        type=str,
        default="finetune_models/bpe.model",
        help="BPE æ¨¡å‹æ–‡ä»¶è·¯å¾„"
    )
    
    args = parser.parse_args()
    
    # åŠ è½½æ¨¡å‹
    if not os.path.exists(args.bpe_model):
        print(f"âŒ BPE æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.bpe_model}")
        return
    
    bpe_model = smp.SentencePieceProcessor()
    bpe_model.Load(args.bpe_model)
    
    print(f"âœ… å·²åŠ è½½ BPE æ¨¡å‹: {args.bpe_model}")
    print(f"ğŸ“Š è¯æ±‡è¡¨å¤§å°: {bpe_model.GetPieceSize()}")

    # è¾“å‡ºè¯æ±‡è¡¨
    #for i in range(bpe_model.GetPieceSize()):
    #    print(f"{i}: {bpe_model.IdToPiece(i)}")

    text = "HELLO"
    tokens = bpe_model.Encode(text, out_type=int)
    print(f"ğŸ“ è¾“å…¥æ–‡æœ¬: '{text}'")
    print(f"ğŸ”¢ Token IDs: {tokens}")
    for i in tokens:
        print(f"{i}: {bpe_model.IdToPiece(i)}")


if __name__ == "__main__":
    main()
